#!/usr/bin/env python3
"""
PDF OCRå®Œæ•´å¤„ç†å™¨ - Sprint 2.3
å®ç°ç«¯åˆ°ç«¯çš„OCRå¤„ç†æµç¨‹
"""

import os
import sys
import logging
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class PDFOCRProcessor:
    """PDF OCRå®Œæ•´å¤„ç†å™¨ - ç«¯åˆ°ç«¯æµç¨‹"""
    
    def __init__(self, lang='eng+chi_sim', enable_preprocessing=True, dpi=200):
        """
        åˆå§‹åŒ–OCRå¤„ç†å™¨
        
        Args:
            lang: OCRè¯­è¨€
            enable_preprocessing: æ˜¯å¦å¯ç”¨å›¾åƒé¢„å¤„ç†
            dpi: OCRå›¾åƒåˆ†è¾¨ç‡
        """
        self.lang = lang
        self.enable_preprocessing = enable_preprocessing
        self.dpi = dpi
        
        # å¯¼å…¥OCRæ¨¡å—
        try:
            from pdf_ocr_module import PDFOCR
            self.ocr = PDFOCR(lang=lang, enable_preprocessing=enable_preprocessing)
            self.ocr_available = self.ocr.is_ocr_available()
            logger.info(f"âœ… OCRå¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸï¼Œè¯­è¨€: {lang}")
        except ImportError:
            self.ocr = None
            self.ocr_available = False
            logger.warning("âš ï¸  OCRæ¨¡å—ä¸å¯ç”¨")
    
    def is_available(self):
        """æ£€æŸ¥OCRåŠŸèƒ½æ˜¯å¦å¯ç”¨"""
        return self.ocr_available
    
    def process_scanned_pdf(self, pdf_path, output_dir=None, pages_per_chapter=20, 
                           sample_pages=3, progress_callback=None):
        """
        å¤„ç†æ‰«æä»¶PDF - å®Œæ•´æµç¨‹
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•ï¼ˆå¦‚ä¸ºNoneåˆ™åªåˆ†æä¸æ‹†åˆ†ï¼‰
            pages_per_chapter: æ¯ç« èŠ‚é¡µæ•°
            sample_pages: é‡‡æ ·åˆ†æé¡µæ•°
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            dict: å¤„ç†ç»“æœ
        """
        start_time = time.time()
        pdf_path = Path(pdf_path)
        
        if not self.is_available():
            logger.error("OCRåŠŸèƒ½ä¸å¯ç”¨ï¼Œæ— æ³•å¤„ç†æ‰«æä»¶")
            return {'success': False, 'error': 'OCRåŠŸèƒ½ä¸å¯ç”¨'}
        
        if not pdf_path.exists():
            logger.error(f"PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
            return {'success': False, 'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}
        
        logger.info(f"ğŸš€ å¼€å§‹å¤„ç†æ‰«æä»¶PDF: {pdf_path.name}")
        logger.info(f"   è¯­è¨€: {self.lang}")
        logger.info(f"   é¢„å¤„ç†: {'å¯ç”¨' if self.enable_preprocessing else 'ç¦ç”¨'}")
        logger.info(f"   åˆ†è¾¨ç‡: {self.dpi} DPI")
        
        # æ­¥éª¤1: åˆ†æPDF
        if progress_callback:
            progress_callback(0, "åˆ†æPDFç±»å‹...")
        
        analysis = self.ocr.analyze_scanned_document(pdf_path, sample_pages)
        scanned_prob = analysis.get('is_scanned_probability', 0)
        
        logger.info(f"ğŸ“Š åˆ†æç»“æœ: æ‰«æä»¶æ¦‚ç‡ {scanned_prob:.1%}")
        
        if scanned_prob < 0.3:
            logger.warning("âš ï¸  æ‰«æä»¶æ¦‚ç‡è¾ƒä½ï¼Œå»ºè®®ä½¿ç”¨æ–‡æœ¬æ¨¡å¼å¤„ç†")
        
        # æ­¥éª¤2: è·å–PDFä¿¡æ¯
        try:
            import PyPDF2
            with open(pdf_path, 'rb') as f:
                pdf_reader = PyPDF2.PdfReader(f)
                total_pages = len(pdf_reader.pages)
                logger.info(f"ğŸ“„ PDFä¿¡æ¯: {total_pages} é¡µ")
        except Exception as e:
            logger.error(f"è·å–PDFä¿¡æ¯å¤±è´¥: {e}")
            return {'success': False, 'error': f'PDFè¯»å–å¤±è´¥: {e}'}
        
        # å¦‚æœä¸éœ€è¦æ‹†åˆ†ï¼Œåªè¿”å›åˆ†æç»“æœ
        if output_dir is None:
            elapsed = time.time() - start_time
            return {
                'success': True,
                'analysis': analysis,
                'total_pages': total_pages,
                'processing_time': elapsed,
                'action': 'analysis_only'
            }
        
        # æ­¥éª¤3: å‡†å¤‡è¾“å‡ºç›®å½•
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # æ­¥éª¤4: OCRå¤„ç†å¹¶æ‹†åˆ†
        if progress_callback:
            progress_callback(10, "å¼€å§‹OCRå¤„ç†...")
        
        chapters = []
        chapter_texts = []  # å­˜å‚¨æ¯ç« èŠ‚çš„OCRæ–‡æœ¬
        
        try:
            # åˆ†ç« èŠ‚å¤„ç†
            num_chapters = (total_pages + pages_per_chapter - 1) // pages_per_chapter
            
            for chapter_idx in range(num_chapters):
                start_page = chapter_idx * pages_per_chapter
                end_page = min(start_page + pages_per_chapter, total_pages)
                
                if progress_callback:
                    progress = 10 + (chapter_idx / num_chapters) * 80
                    progress_callback(int(progress), f"å¤„ç†ç¬¬ {chapter_idx + 1}/{num_chapters} ç« ...")
                
                logger.info(f"å¤„ç†ç¬¬ {chapter_idx + 1} ç« : é¡µ {start_page + 1}-{end_page}")
                
                # æå–æœ¬ç« èŠ‚çš„OCRæ–‡æœ¬
                chapter_text = ""
                for page_num in range(start_page, end_page):
                    try:
                        # ä½¿ç”¨å¸¦é¢„å¤„ç†çš„OCRæå–
                        page_text = self.ocr.extract_text_with_preprocessing(pdf_path, page_num)
                        if page_text:
                            chapter_text += f"\n--- ç¬¬ {page_num + 1} é¡µ ---\n{page_text}\n"
                    except Exception as e:
                        logger.warning(f"ç¬¬ {page_num + 1} é¡µOCRå¤±è´¥: {e}")
                        chapter_text += f"\n--- ç¬¬ {page_num + 1} é¡µ [OCRå¤±è´¥] ---\n"
                
                chapter_texts.append(chapter_text)
                
                # ä¿å­˜ç« èŠ‚æ–‡æœ¬
                text_filename = f"{pdf_path.stem}_chapter_{chapter_idx + 1:03d}.txt"
                text_path = output_dir / text_filename
                
                with open(text_path, 'w', encoding='utf-8') as f:
                    f.write(chapter_text)
                
                logger.info(f"  ä¿å­˜æ–‡æœ¬: {text_filename} ({len(chapter_text)} å­—ç¬¦)")
                
                # åˆ›å»ºç« èŠ‚PDFï¼ˆä½¿ç”¨åŸå§‹PDFé¡µé¢ï¼‰
                try:
                    import PyPDF2
                    with open(pdf_path, 'rb') as f:
                        pdf_reader = PyPDF2.PdfReader(f)
                        chapter_pdf = PyPDF2.PdfWriter()
                        
                        for page_num in range(start_page, end_page):
                            page = pdf_reader.pages[page_num]
                            chapter_pdf.add_page(page)
                        
                        pdf_filename = f"{pdf_path.stem}_chapter_{chapter_idx + 1:03d}.pdf"
                        pdf_path_out = output_dir / pdf_filename
                        
                        with open(pdf_path_out, 'wb') as pdf_file:
                            chapter_pdf.write(pdf_file)
                        
                        chapters.append(str(pdf_path_out))
                        logger.info(f"  ä¿å­˜PDF: {pdf_filename}")
                        
                except Exception as e:
                    logger.error(f"åˆ›å»ºç« èŠ‚PDFå¤±è´¥: {e}")
                    # ç»§ç»­å¤„ç†ï¼Œè‡³å°‘ä¿å­˜äº†æ–‡æœ¬
            
            # æ­¥éª¤5: ç”Ÿæˆå¤„ç†æŠ¥å‘Š
            if progress_callback:
                progress_callback(95, "ç”ŸæˆæŠ¥å‘Š...")
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_text_chars = sum(len(text) for text in chapter_texts)
            avg_chars_per_page = total_text_chars / total_pages if total_pages > 0 else 0
            
            report = {
                'pdf_name': pdf_path.name,
                'total_pages': total_pages,
                'chapters_created': len(chapters),
                'pages_per_chapter': pages_per_chapter,
                'total_text_chars': total_text_chars,
                'avg_chars_per_page': avg_chars_per_page,
                'scanned_probability': scanned_prob,
                'output_dir': str(output_dir),
                'text_files': [str(output_dir / f"{pdf_path.stem}_chapter_{i+1:03d}.txt") 
                              for i in range(len(chapter_texts))],
                'pdf_files': chapters,
                'processing_time': time.time() - start_time
            }
            
            # ä¿å­˜æŠ¥å‘Š
            report_filename = f"{pdf_path.stem}_ocr_report.json"
            report_path = output_dir / report_filename
            
            import json
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ“‹ å¤„ç†æŠ¥å‘Š: {report_filename}")
            
            if progress_callback:
                progress_callback(100, "å¤„ç†å®Œæˆ!")
            
            logger.info(f"âœ… æ‰«æä»¶PDFå¤„ç†å®Œæˆ!")
            logger.info(f"   å¤„ç†æ—¶é—´: {report['processing_time']:.1f} ç§’")
            logger.info(f"   ç”Ÿæˆç« èŠ‚: {len(chapters)}")
            logger.info(f"   æ€»æ–‡æœ¬å­—ç¬¦: {total_text_chars}")
            logger.info(f"   è¾“å‡ºç›®å½•: {output_dir}")
            
            report['success'] = True
            return report
            
        except Exception as e:
            logger.error(f"å¤„ç†æ‰«æä»¶PDFæ—¶å‡ºé”™: {e}")
            return {'success': False, 'error': str(e)}
    
    def batch_process(self, pdf_files, output_base_dir, **kwargs):
        """
        æ‰¹é‡å¤„ç†å¤šä¸ªPDFæ–‡ä»¶
        
        Args:
            pdf_files: PDFæ–‡ä»¶è·¯å¾„åˆ—è¡¨
            output_base_dir: è¾“å‡ºåŸºç¡€ç›®å½•
            **kwargs: ä¼ é€’ç»™process_scanned_pdfçš„å‚æ•°
            
        Returns:
            dict: æ‰¹é‡å¤„ç†ç»“æœ
        """
        output_base_dir = Path(output_base_dir)
        output_base_dir.mkdir(parents=True, exist_ok=True)
        
        results = {
            'total_files': len(pdf_files),
            'successful': 0,
            'failed': 0,
            'details': [],
            'start_time': datetime.now().isoformat()
        }
        
        for i, pdf_file in enumerate(pdf_files):
            pdf_path = Path(pdf_file)
            if not pdf_path.exists():
                logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
                results['details'].append({
                    'file': str(pdf_path),
                    'success': False,
                    'error': 'æ–‡ä»¶ä¸å­˜åœ¨'
                })
                results['failed'] += 1
                continue
            
            logger.info(f"å¤„ç†æ–‡ä»¶ {i+1}/{len(pdf_files)}: {pdf_path.name}")
            
            # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºå•ç‹¬çš„è¾“å‡ºç›®å½•
            file_output_dir = output_base_dir / pdf_path.stem
            file_output_dir.mkdir(exist_ok=True)
            
            try:
                result = self.process_scanned_pdf(
                    pdf_path, 
                    output_dir=file_output_dir,
                    **kwargs
                )
                
                if result.get('success', False):
                    results['successful'] += 1
                    logger.info(f"âœ… å¤„ç†æˆåŠŸ: {pdf_path.name}")
                else:
                    results['failed'] += 1
                    logger.error(f"âŒ å¤„ç†å¤±è´¥: {pdf_path.name}")
                
                result['file'] = str(pdf_path)
                results['details'].append(result)
                
            except Exception as e:
                logger.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™ {pdf_path.name}: {e}")
                results['details'].append({
                    'file': str(pdf_path),
                    'success': False,
                    'error': str(e)
                })
                results['failed'] += 1
        
        results['end_time'] = datetime.now().isoformat()
        
        # ä¿å­˜æ‰¹é‡å¤„ç†æŠ¥å‘Š
        report_path = output_base_dir / 'batch_processing_report.json'
        import json
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆ:")
        logger.info(f"   æ€»æ–‡ä»¶: {results['total_files']}")
        logger.info(f"   æˆåŠŸ: {results['successful']}")
        logger.info(f"   å¤±è´¥: {results['failed']}")
        logger.info(f"   æŠ¥å‘Š: {report_path}")
        
        return results

def test_ocr_processor():
    """æµ‹è¯•OCRå¤„ç†å™¨"""
    print("ğŸ§ª æµ‹è¯•OCRå®Œæ•´å¤„ç†å™¨")
    
    processor = PDFOCRProcessor()
    
    if not processor.is_available():
        print("âŒ OCRåŠŸèƒ½ä¸å¯ç”¨")
        print("è¯·å®‰è£…ä¾èµ–: pip install pytesseract pdf2image Pillow PyPDF2")
        return False
    
    print("âœ… OCRå¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
    
    # æ£€æŸ¥æµ‹è¯•PDF
    test_dir = Path("test_pdf_files")
    if test_dir.exists():
        pdf_files = list(test_dir.glob("*.pdf"))
        if pdf_files:
            test_pdf = pdf_files[0]
            print(f"\nğŸ“‹ æ‰¾åˆ°æµ‹è¯•PDF: {test_pdf.name}")
            print("è¿è¡Œå®Œæ•´å¤„ç†æµ‹è¯•:")
            print(f"  python pdf_chapter_splitter_final.py -i {test_pdf} --ocr-full")
        else:
            print("\nğŸ“‹ æµ‹è¯•ç›®å½•ä¸­æ²¡æœ‰PDFæ–‡ä»¶")
    else:
        print("\nğŸ“‹ æµ‹è¯•ç›®å½•ä¸å­˜åœ¨")
    
    return True

def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(description='PDF OCRå®Œæ•´å¤„ç†å™¨')
    parser.add_argument('--test', action='store_true', help='æµ‹è¯•OCRåŠŸèƒ½')
    parser.add_argument('--pdf', type=str, help='PDFæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', type=str, help='è¾“å‡ºç›®å½•')
    parser.add_argument('--pages', '-p', type=int, default=20, help='æ¯ç« èŠ‚é¡µæ•°')
    parser.add_argument('--lang', type=str, default='eng+chi_sim', help='OCRè¯­è¨€')
    
    args = parser.parse_args()
    
    if args.test:
        test_ocr_processor()
        return
    
    if args.pdf and args.output:
        processor = PDFOCRProcessor(lang=args.lang)
        
        if not processor.is_available():
            print("âŒ OCRåŠŸèƒ½ä¸å¯ç”¨")
            print("è¯·å®‰è£…ä¾èµ–: pip install pytesseract pdf2image Pillow")
            return
        
        print(f"ğŸš€ å¼€å§‹å¤„ç†: {args.pdf}")
        print(f"   è¾“å‡ºåˆ°: {args.output}")
        print(f"   è¯­è¨€: {args.lang}")
        print(f"   æ¯ç« èŠ‚é¡µæ•°: {args.pages}")
        
        def progress_callback(percent, message):
            print(f"è¿›åº¦: {percent}% - {message}")
        
        result = processor.process_scanned_pdf(
            args.pdf,
            args.output,
            pages_per_chapter=args.pages,
            progress_callback=progress_callback
        )
        
        if result.get('success', False):
            print(f"\nâœ… å¤„ç†æˆåŠŸ!")
            print(f"   ç« èŠ‚æ•°: {result.get('chapters_created', 0)}")
            print(f"   å¤„ç†æ—¶é—´: {result.get('processing_time', 0):.1f}ç§’")
            print(f"   è¾“å‡ºç›®å½•: {result.get('output_dir', '')}")
        else:
            print(f"\nâŒ å¤„ç†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    
    else:
        parser.print_help()

if __name__ == "__main__":
    main()