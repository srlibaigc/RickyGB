#!/usr/bin/env python3
"""
Markdownæ–‡ä»¶åˆå¹¶å·¥å…·
å°†ç›®å½•ä¸‹çš„æ‰€æœ‰.mdæ–‡ä»¶åˆå¹¶ä¸ºä¸€ä¸ªå¸¦ç›®å½•çš„.mdæ–‡ä»¶
"""

import sys
import argparse
import re
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Tuple

SRC_ROOT = Path(__file__).resolve().parents[1]
if str(SRC_ROOT) not in sys.path:
    sys.path.insert(0, str(SRC_ROOT))

from utils.logging_utils import setup_logging, get_logger


logger = get_logger(__name__)

class MarkdownMerger:
    """Markdownæ–‡ä»¶åˆå¹¶å™¨"""
    
    def __init__(self):
        self.file_count = 0
        self.total_lines = 0
        
    def find_markdown_files(self, directory: Path, recursive: bool = True) -> List[Path]:
        """
        æŸ¥æ‰¾ç›®å½•ä¸­çš„æ‰€æœ‰Markdownæ–‡ä»¶
        
        Args:
            directory: ç›®å½•è·¯å¾„
            recursive: æ˜¯å¦é€’å½’æŸ¥æ‰¾å­ç›®å½•
            
        Returns:
            Markdownæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        md_files = []
        
        if recursive:
            # é€’å½’æŸ¥æ‰¾æ‰€æœ‰.mdæ–‡ä»¶
            for md_file in directory.rglob("*.md"):
                if md_file.is_file():
                    md_files.append(md_file)
        else:
            # åªæŸ¥æ‰¾å½“å‰ç›®å½•
            for md_file in directory.glob("*.md"):
                if md_file.is_file():
                    md_files.append(md_file)
        
        # æŒ‰æ–‡ä»¶åæ’åºï¼ˆè‡ªç„¶æ’åºï¼‰
        md_files.sort(key=lambda x: x.name.lower())
        
        return md_files
    
    def extract_title_from_file(self, file_path: Path) -> Tuple[str, str]:
        """
        ä»Markdownæ–‡ä»¶ä¸­æå–æ ‡é¢˜
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            (æ ‡é¢˜, æå–æ–¹æ³•)
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # æ–¹æ³•1: æŸ¥æ‰¾ç¬¬ä¸€ä¸ªä¸€çº§æ ‡é¢˜
            match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
            if match:
                return match.group(1).strip(), "ä¸€çº§æ ‡é¢˜"
            
            # æ–¹æ³•2: æŸ¥æ‰¾ç¬¬ä¸€ä¸ªäºŒçº§æ ‡é¢˜
            match = re.search(r'^##\s+(.+)$', content, re.MULTILINE)
            if match:
                return match.group(1).strip(), "äºŒçº§æ ‡é¢˜"
            
            # æ–¹æ³•3: ä½¿ç”¨ç¬¬ä¸€è¡Œéç©ºè¡Œ
            lines = content.strip().split('\n')
            for line in lines:
                if line.strip():
                    # ç§»é™¤Markdownæ ‡è®°
                    clean_line = re.sub(r'^#+\s*', '', line.strip())
                    if clean_line:
                        return clean_line[:100], "ç¬¬ä¸€è¡Œ"
            
            # æ–¹æ³•4: ä½¿ç”¨æ–‡ä»¶å
            return file_path.stem.replace('_', ' ').replace('-', ' ').title(), "æ–‡ä»¶å"
            
        except Exception as e:
            logger.warning(
                "æå–æ ‡é¢˜å¤±è´¥ï¼Œä½¿ç”¨æ–‡ä»¶åå…œåº• | file=%s | reason=%s",
                file_path,
                e,
            )
            return file_path.stem, "æ–‡ä»¶åï¼ˆé”™è¯¯ï¼‰"
    
    def generate_table_of_contents(self, files: List[Path], base_dir: Path) -> str:
        """
        ç”Ÿæˆç›®å½•
        
        Args:
            files: æ–‡ä»¶åˆ—è¡¨
            base_dir: åŸºç¡€ç›®å½•ï¼ˆç”¨äºè®¡ç®—ç›¸å¯¹è·¯å¾„ï¼‰
            
        Returns:
            ç›®å½•Markdownæ–‡æœ¬
        """
        if not files:
            return "## ç›®å½•\n\nï¼ˆæ— Markdownæ–‡ä»¶ï¼‰\n\n"
        
        toc_lines = ["## ğŸ“š ç›®å½•\n\n"]
        
        for i, file_path in enumerate(files, 1):
            # è®¡ç®—ç›¸å¯¹è·¯å¾„
            rel_path = file_path.relative_to(base_dir) if file_path.is_relative_to(base_dir) else file_path
            
            # æå–æ ‡é¢˜
            title, method = self.extract_title_from_file(file_path)
            
            # åˆ›å»ºç›®å½•é¡¹
            toc_lines.append(f"{i}. **[{title}](#{self.slugify(title)})**  \n")
            toc_lines.append(f"   `{rel_path}`  \n")
        
        toc_lines.append("\n---\n\n")
        return ''.join(toc_lines)
    
    def slugify(self, text: str) -> str:
        """
        å°†æ–‡æœ¬è½¬æ¢ä¸ºURLå‹å¥½çš„slug
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            slugå­—ç¬¦ä¸²
        """
        # è½¬æ¢ä¸ºå°å†™ï¼Œæ›¿æ¢ç©ºæ ¼ä¸ºè¿å­—ç¬¦ï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦
        slug = text.lower()
        slug = re.sub(r'[^\w\s-]', '', slug)  # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
        slug = re.sub(r'[\s_-]+', '-', slug)  # æ›¿æ¢ç©ºæ ¼å’Œè¿å­—ç¬¦
        slug = slug.strip('-')  # ç§»é™¤é¦–å°¾è¿å­—ç¬¦
        return slug
    
    def merge_files(self, input_dir: Path, output_file: Path, 
                   recursive: bool = True, 
                   include_toc: bool = True,
                   add_separators: bool = True) -> Dict:
        """
        åˆå¹¶Markdownæ–‡ä»¶
        
        Args:
            input_dir: è¾“å…¥ç›®å½•
            output_file: è¾“å‡ºæ–‡ä»¶
            recursive: æ˜¯å¦é€’å½’æŸ¥æ‰¾
            include_toc: æ˜¯å¦åŒ…å«ç›®å½•
            add_separators: æ˜¯å¦æ·»åŠ æ–‡ä»¶åˆ†éš”ç¬¦
            
        Returns:
            åˆå¹¶ç»Ÿè®¡ä¿¡æ¯
        """
        # éªŒè¯è¾“å…¥ç›®å½•
        if not input_dir.exists():
            raise FileNotFoundError(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        
        if not input_dir.is_dir():
            raise ValueError(f"è¾“å…¥è·¯å¾„ä¸æ˜¯ç›®å½•: {input_dir}")
        
        # æŸ¥æ‰¾Markdownæ–‡ä»¶
        md_files = self.find_markdown_files(input_dir, recursive)
        
        if not md_files:
            logger.warning("ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°Markdownæ–‡ä»¶ | input_dir=%s", input_dir)
            return {'success': False, 'error': 'æ²¡æœ‰æ‰¾åˆ°.mdæ–‡ä»¶'}

        logger.info("å‘ç°Markdownæ–‡ä»¶ | count=%s | input_dir=%s", len(md_files), input_dir)
        
        # å‡†å¤‡è¾“å‡º
        output_content = []
        stats = {
            'input_dir': str(input_dir),
            'output_file': str(output_file),
            'file_count': len(md_files),
            'files_processed': [],
            'start_time': datetime.now().isoformat(),
            'total_lines': 0,
            'total_size': 0
        }
        
        # æ·»åŠ æ–‡ä»¶å¤´
        output_content.append(f"# ğŸ“„ åˆå¹¶Markdownæ–‡æ¡£\n\n")
        output_content.append(f"**æ¥æºç›®å½•**: `{input_dir}`  \n")
        output_content.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  \n")
        output_content.append(f"**æ–‡ä»¶æ•°é‡**: {len(md_files)}  \n\n")
        output_content.append("---\n\n")
        
        # æ·»åŠ ç›®å½•
        if include_toc:
            toc = self.generate_table_of_contents(md_files, input_dir)
            output_content.append(toc)
        
        # åˆå¹¶æ–‡ä»¶å†…å®¹
        for i, file_path in enumerate(md_files, 1):
            file_start_time = datetime.now()
            
            try:
                # è¯»å–æ–‡ä»¶å†…å®¹
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # è®¡ç®—æ–‡ä»¶ä¿¡æ¯
                file_size = file_path.stat().st_size
                file_lines = content.count('\n') + 1
                
                # æå–æ ‡é¢˜
                title, method = self.extract_title_from_file(file_path)
                
                # è®¡ç®—ç›¸å¯¹è·¯å¾„
                rel_path = file_path.relative_to(input_dir) if file_path.is_relative_to(input_dir) else file_path
                
                # æ·»åŠ æ–‡ä»¶åˆ†éš”ç¬¦
                if add_separators and i > 1:
                    output_content.append("\n" + "=" * 80 + "\n\n")
                
                # æ·»åŠ æ–‡ä»¶æ ‡é¢˜å’Œå…ƒä¿¡æ¯
                output_content.append(f"## ğŸ“ {title}\n\n")
                output_content.append(f"**æ–‡ä»¶**: `{rel_path}`  \n")
                output_content.append(f"**å¤§å°**: {file_size:,} å­—èŠ‚  \n")
                output_content.append(f"**è¡Œæ•°**: {file_lines} è¡Œ  \n")
                output_content.append(f"**æ ‡é¢˜æ¥æº**: {method}  \n")
                output_content.append(f"**åˆå¹¶é¡ºåº**: ç¬¬ {i} ä¸ªæ–‡ä»¶  \n\n")
                output_content.append("---\n\n")
                
                # æ·»åŠ æ–‡ä»¶å†…å®¹
                output_content.append(content)
                
                # ç¡®ä¿å†…å®¹ä»¥æ¢è¡Œç»“æŸ
                if not content.endswith('\n'):
                    output_content.append('\n')
                
                # æ›´æ–°ç»Ÿè®¡
                self.file_count += 1
                self.total_lines += file_lines
                
                # è®°å½•æ–‡ä»¶å¤„ç†ä¿¡æ¯
                file_stats = {
                    'file': str(file_path),
                    'relative_path': str(rel_path),
                    'title': title,
                    'title_source': method,
                    'size': file_size,
                    'lines': file_lines,
                    'order': i,
                    'processing_time': (datetime.now() - file_start_time).total_seconds()
                }
                stats['files_processed'].append(file_stats)
                stats['total_lines'] += file_lines
                stats['total_size'] += file_size

                logger.info(
                    "æ–‡ä»¶å¤„ç†å®Œæˆ | order=%s/%s | relative_path=%s | title=%s | title_source=%s | size_bytes=%s | lines=%s | elapsed_seconds=%.3f",
                    i,
                    len(md_files),
                    rel_path,
                    title,
                    method,
                    file_size,
                    file_lines,
                    file_stats['processing_time'],
                )

            except Exception as e:
                logger.error(
                    "æ–‡ä»¶å¤„ç†å¤±è´¥ | file=%s | order=%s/%s | elapsed_seconds=%.3f | reason=%s",
                    file_path,
                    i,
                    len(md_files),
                    (datetime.now() - file_start_time).total_seconds(),
                    e,
                )
                
                # æ·»åŠ é”™è¯¯ä¿¡æ¯åˆ°è¾“å‡º
                output_content.append(f"## âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {file_path.name}\n\n")
                output_content.append(f"é”™è¯¯: {e}\n\n")
                output_content.append("---\n\n")
        
        # æ·»åŠ æ–‡ä»¶å°¾
        output_content.append("\n" + "=" * 80 + "\n\n")
        output_content.append("## ğŸ“Š åˆå¹¶ç»Ÿè®¡\n\n")
        output_content.append(f"**æ€»æ–‡ä»¶æ•°**: {len(md_files)}  \n")
        output_content.append(f"**æ€»è¡Œæ•°**: {stats['total_lines']:,}  \n")
        output_content.append(f"**æ€»å¤§å°**: {stats['total_size']:,} å­—èŠ‚  \n")
        output_content.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  \n")
        output_content.append(f"**å¤„ç†è€—æ—¶**: {(datetime.now() - datetime.fromisoformat(stats['start_time'])).total_seconds():.1f} ç§’  \n\n")
        
        # å†™å…¥è¾“å‡ºæ–‡ä»¶
        try:
            output_file.parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(''.join(output_content))

            output_size = output_file.stat().st_size
            logger.info(
                "åˆå¹¶è¾“å‡ºå†™å…¥å®Œæˆ | output_file=%s | output_size_bytes=%s | file_count=%s | total_lines=%s",
                output_file,
                output_size,
                len(md_files),
                stats['total_lines'],
            )
            
            stats['success'] = True
            stats['output_size'] = output_size
            stats['end_time'] = datetime.now().isoformat()
            stats['processing_time'] = (datetime.fromisoformat(stats['end_time']) - 
                                       datetime.fromisoformat(stats['start_time'])).total_seconds()
            
            return stats

        except Exception as e:
            logger.error(
                "å†™å…¥è¾“å‡ºæ–‡ä»¶å¤±è´¥ | output_file=%s | reason=%s",
                output_file,
                e,
            )
            return {'success': False, 'error': str(e)}

def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    parser = argparse.ArgumentParser(
        description='åˆå¹¶ç›®å½•ä¸­çš„Markdownæ–‡ä»¶ä¸ºä¸€ä¸ªå¸¦ç›®å½•çš„æ–‡ä»¶',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åˆå¹¶å½“å‰ç›®å½•çš„æ‰€æœ‰.mdæ–‡ä»¶
  python merge_markdown.py --dir . --output merged.md
  
  # é€’å½’åˆå¹¶å­ç›®å½•
  python merge_markdown.py --dir docs --output combined.md --recursive
  
  # ä¸ç”Ÿæˆç›®å½•
  python merge_markdown.py --dir . --output simple.md --no-toc
  
  # è¾“å‡ºæœ€ç»ˆæ‘˜è¦ï¼ˆé»˜è®¤å…³é—­ï¼‰
  python merge_markdown.py --dir docs --output combined.md --print-summary

  # ç”Ÿæˆç¤ºä¾‹Markdownæ–‡ä»¶
  python generate_sample_markdown.py --output-dir sample_markdown --count 3
        """
    )
    
    # ä¸»è¦å‚æ•°
    parser.add_argument('--dir', '-d', type=str, default='.',
                       help='è¾“å…¥ç›®å½•è·¯å¾„ (é»˜è®¤: å½“å‰ç›®å½•)')
    parser.add_argument('--output', '-o', type=str, default='merged_document.md',
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ (é»˜è®¤: merged_document.md)')
    
    # é€‰é¡¹å‚æ•°
    parser.add_argument('--recursive', '-r', action='store_true',
                       help='é€’å½’æŸ¥æ‰¾å­ç›®å½•ä¸­çš„.mdæ–‡ä»¶')
    parser.add_argument('--no-toc', action='store_true',
                       help='ä¸ç”Ÿæˆç›®å½•')
    parser.add_argument('--no-separators', action='store_true',
                       help='ä¸æ·»åŠ æ–‡ä»¶åˆ†éš”ç¬¦')
    parser.add_argument('--log-level', type=str, default='INFO',
                       choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'],
                       help='æ—¥å¿—çº§åˆ« (é»˜è®¤: INFO)')
    parser.add_argument('--log-file', type=str, default=None,
                       help='å¯é€‰æ—¥å¿—æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--print-summary', action='store_true',
                       help='è¾“å‡ºCLIæœ€ç»ˆæ‘˜è¦')

    args = parser.parse_args()

    setup_logging(level=args.log_level, log_file=args.log_file)

    merger = MarkdownMerger()

    # æ­£å¸¸åˆå¹¶æ¨¡å¼
    input_dir = Path(args.dir)
    output_file = Path(args.output)

    logger.info(
        "å¼€å§‹åˆå¹¶Markdownæ–‡ä»¶ | input_dir=%s | output_file=%s | recursive=%s | include_toc=%s | add_separators=%s",
        input_dir,
        output_file,
        args.recursive,
        not args.no_toc,
        not args.no_separators,
    )
    
    try:
        result = merger.merge_files(
            input_dir,
            output_file,
            recursive=args.recursive,
            include_toc=not args.no_toc,
            add_separators=not args.no_separators
        )

        if result.get('success', False):
            logger.info(
                "Markdownåˆå¹¶æ‰§è¡ŒæˆåŠŸ | output_file=%s | file_count=%s | total_lines=%s | processing_time_seconds=%.3f",
                output_file,
                result['file_count'],
                result['total_lines'],
                result['processing_time'],
            )
            if args.print_summary:
                print(f"âœ… åˆå¹¶å®Œæˆ: {output_file}")
                print(
                    f"æ–‡ä»¶æ•°={result['file_count']} | æ€»è¡Œæ•°={result['total_lines']:,} | "
                    f"å¤„ç†æ—¶é—´={result['processing_time']:.1f}s"
                )
            return 0
        else:
            logger.error(
                "Markdownåˆå¹¶æ‰§è¡Œå¤±è´¥ | input_dir=%s | output_file=%s | reason=%s",
                input_dir,
                output_file,
                result.get('error', 'æœªçŸ¥é”™è¯¯'),
            )
            if args.print_summary:
                print(f"âŒ åˆå¹¶å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return 1

    except Exception as e:
        logger.exception(
            "åˆå¹¶è¿‡ç¨‹ä¸­å‘ç”Ÿæœªæ•è·å¼‚å¸¸ | input_dir=%s | output_file=%s | reason=%s",
            input_dir,
            output_file,
            e,
        )
        if args.print_summary:
            print(f"ğŸ’¥ åˆå¹¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(main())
