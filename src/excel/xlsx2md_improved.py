#!/usr/bin/env python3
"""
XLSX to Markdown Converter - æ”¹è¿›ç‰ˆ
ä½¿ç”¨ç»Ÿä¸€çš„å·¥å…·æ¨¡å—ï¼Œä»£ç æ›´ç®€æ´ï¼ŒåŠŸèƒ½æ›´å¼ºå¤§
"""

import argparse
import sys
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional
import warnings
from tqdm import tqdm
from datetime import datetime

# å¯¼å…¥å·¥å…·æ¨¡å—
try:
    from utils import (
        safe_json_loads, safe_json_dumps,
        ensure_directory, safe_write_file, get_file_hash,
        setup_logging, get_logger, ProgressTracker
    )
    TOOLS_AVAILABLE = True
except ImportError:
    TOOLS_AVAILABLE = False
    import json
    import hashlib
    import logging
    
    # ç®€å•çš„å›é€€å®ç°
    def safe_json_loads(text, default=None):
        if default is None:
            default = {}
        try:
            return json.loads(text)
        except:
            return default
    
    def safe_json_dumps(obj, **kwargs):
        return json.dumps(obj, **kwargs)
    
    def ensure_directory(path):
        Path(path).mkdir(parents=True, exist_ok=True)
        return Path(path)
    
    def safe_write_file(file_path, content, encoding='utf-8', backup=False):
        path = Path(file_path)
        ensure_directory(path.parent)
        with open(path, 'w', encoding=encoding) as f:
            f.write(content)
        return path
    
    def get_file_hash(file_path, algorithm='sha256'):
        path = Path(file_path)
        hash_func = getattr(hashlib, algorithm, hashlib.sha256)
        with open(path, 'rb') as f:
            return hash_func(f.read()).hexdigest()
    
    def setup_logging(level="INFO", **kwargs):
        logging.basicConfig(level=getattr(logging, level.upper()), 
                          format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        return logging.getLogger()
    
    def get_logger(name):
        return logging.getLogger(name)
    
    class ProgressTracker:
        def __init__(self, total, description="å¤„ç†è¿›åº¦"):
            self.total = total
            self.description = description
            self.current = 0
        
        def update(self, increment=1):
            self.current += increment
        
        def complete(self):
            pass

warnings.filterwarnings('ignore')

# è®¾ç½®æ—¥å¿—
logger = get_logger(__name__)


class ExcelToMarkdownConverter:
    """Excelæ–‡ä»¶è½¬Markdownè½¬æ¢å™¨ - æ”¹è¿›ç‰ˆ"""
    
    def __init__(self, chunk_size: int = 1000, max_rows_per_page: int = 500):
        """
        åˆå§‹åŒ–è½¬æ¢å™¨
        
        Args:
            chunk_size: åˆ†å—å¤„ç†çš„è¡Œæ•°
            max_rows_per_page: æ¯ä¸ªMarkdowné¡µé¢çš„æœ€å¤§è¡Œæ•°
        """
        self.chunk_size = chunk_size
        self.max_rows_per_page = max_rows_per_page
        logger.info(f"åˆå§‹åŒ–è½¬æ¢å™¨: chunk_size={chunk_size}, max_rows_per_page={max_rows_per_page}")
    
    def get_engine_for_file(self, file_path: str) -> str:
        """æ ¹æ®æ–‡ä»¶æ‰©å±•åè·å–åˆé€‚çš„å¼•æ“"""
        ext = Path(file_path).suffix.lower()
        
        if ext == '.xlsx':
            return 'openpyxl'
        elif ext == '.xls':
            try:
                import xlrd
                return 'xlrd'
            except ImportError:
                logger.warning("xlrdæœªå®‰è£…ï¼Œå°è¯•ä½¿ç”¨openpyxlè¯»å–.xlsæ–‡ä»¶")
                return 'openpyxl'
        else:
            return 'openpyxl'
    
    def read_excel_file(self, file_path: str) -> Dict[str, pd.DataFrame]:
        """
        å®‰å…¨è¯»å–Excelæ–‡ä»¶
        
        Args:
            file_path: Excelæ–‡ä»¶è·¯å¾„
            
        Returns:
            åŒ…å«sheetåå’ŒDataFrameçš„å­—å…¸
        """
        file_name = Path(file_path).name
        logger.info(f"å¼€å§‹è¯»å–Excelæ–‡ä»¶: {file_name}")
        
        engines_to_try = []
        ext = Path(file_path).suffix.lower()
        
        if ext == '.xlsx':
            engines_to_try = ['openpyxl', 'xlrd']
        elif ext == '.xls':
            engines_to_try = ['xlrd', 'openpyxl']
        else:
            engines_to_try = ['openpyxl', 'xlrd']
        
        for engine in engines_to_try:
            try:
                logger.debug(f"å°è¯•ä½¿ç”¨ {engine} å¼•æ“")
                excel_file = pd.ExcelFile(file_path, engine=engine)
                sheets = {}
                
                for sheet_name in excel_file.sheet_names:
                    try:
                        df = pd.read_excel(
                            excel_file,
                            sheet_name=sheet_name,
                            dtype=str,
                            na_filter=False,
                            engine=engine
                        )
                        sheets[sheet_name] = df
                        logger.debug(f"è¯»å–sheeté¡µ: {sheet_name} ({len(df)}è¡ŒÃ—{len(df.columns)}åˆ—)")
                    except Exception as e:
                        logger.warning(f"è¯»å–sheeté¡µ {sheet_name} å¤±è´¥: {e}")
                        sheets[sheet_name] = pd.DataFrame()
                
                logger.info(f"æˆåŠŸè¯»å–æ–‡ä»¶: {file_name} (å¼•æ“: {engine}, sheeté¡µ: {len(sheets)})")
                return sheets
                
            except ImportError:
                logger.debug(f"å¼•æ“ {engine} ä¸å¯ç”¨")
                continue
            except Exception as e:
                logger.warning(f"ä½¿ç”¨å¼•æ“ {engine} è¯»å–å¤±è´¥: {e}")
                continue
        
        raise ValueError(f"æ— æ³•è¯»å–Excelæ–‡ä»¶: {file_name}")
    
    def should_skip_conversion(self, input_file: Path, output_file: Path) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡è½¬æ¢ï¼ˆå¹‚ç­‰æ£€æµ‹ï¼‰
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦åº”è¯¥è·³è¿‡
        """
        if not output_file.exists():
            return False
        
        try:
            content = safe_write_file.__wrapped__.__globals__.get('safe_read_file', 
                lambda p: Path(p).read_text(encoding='utf-8'))(output_file)
            
            import re
            json_match = re.search(r'```json\s*(.*?)\s*```', content, re.DOTALL)
            
            if json_match:
                summary = safe_json_loads(json_match.group(1), default={})
                if summary.get('file_name') == input_file.name:
                    logger.info(f"æ£€æµ‹åˆ°å·²è½¬æ¢æ–‡ä»¶: {input_file.name}")
                    return True
        except Exception as e:
            logger.debug(f"å¹‚ç­‰æ£€æµ‹å¤±è´¥: {e}")
        
        return False
    
    def convert_single_file(self, input_path: str, output_path: str, force: bool = False) -> bool:
        """
        è½¬æ¢å•ä¸ªExcelæ–‡ä»¶
        
        Args:
            input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°è½¬æ¢
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        input_file = Path(input_path)
        output_file = Path(output_path)
        
        if not input_file.exists():
            logger.error(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
            return False
        
        # å¹‚ç­‰æ£€æµ‹
        if not force and self.should_skip_conversion(input_file, output_file):
            print(f"âœ“ è·³è¿‡å·²è½¬æ¢æ–‡ä»¶: {input_file.name}")
            return True
        
        print(f"å¤„ç†æ–‡ä»¶: {input_file.name}")
        
        try:
            # è¯»å–Excelæ–‡ä»¶
            sheets = self.read_excel_file(input_path)
            
            if not sheets:
                logger.error(f"Excelæ–‡ä»¶æ²¡æœ‰å¯è¯»å–çš„æ•°æ®: {input_path}")
                return False
            
            # ç”ŸæˆMarkdownå†…å®¹
            markdown_content = self._generate_markdown(input_file, sheets)
            
            # å†™å…¥æ–‡ä»¶
            safe_write_file(output_file, markdown_content, backup=True)
            
            print(f"âœ“ è½¬æ¢å®Œæˆ: {output_file.name}")
            return True
            
        except Exception as e:
            logger.error(f"è½¬æ¢æ–‡ä»¶ {input_path} æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _generate_markdown(self, input_file: Path, sheets: Dict[str, pd.DataFrame]) -> str:
        """
        ç”ŸæˆMarkdownå†…å®¹
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            sheets: Excelæ•°æ®å­—å…¸
            
        Returns:
            Markdownå†…å®¹
        """
        lines = []
        
        # æ–‡ä»¶å¤´
        lines.append(f"# Excelè½¬Markdown - {input_file.stem}")
        lines.append("")
        lines.append(f"**æºæ–‡ä»¶**: `{input_file.name}`")
        lines.append(f"**è½¬æ¢æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"**æ–‡ä»¶å“ˆå¸Œ**: {get_file_hash(input_file)}")
        lines.append("")
        
        # sheeté¡µä¿¡æ¯
        total_rows = sum(len(df) for df in sheets.values())
        total_columns = sum(len(df.columns) for df in sheets.values())
        
        lines.append(f"**æ€»sheeté¡µ**: {len(sheets)}")
        lines.append(f"**æ€»è¡Œæ•°**: {total_rows:,}")
        lines.append(f"**æ€»åˆ—æ•°**: {total_columns:,}")
        lines.append("")
        
        # æ¯ä¸ªsheeté¡µçš„å†…å®¹
        progress = ProgressTracker(len(sheets), "å¤„ç†sheeté¡µ")
        
        for sheet_name, df in sheets.items():
            lines.append(f"## ğŸ“„ {sheet_name}")
            lines.append("")
            
            # sheeté¡µç»Ÿè®¡
            lines.append(f"*è¡Œæ•°*: {len(df):,} | *åˆ—æ•°*: {len(df.columns):,}")
            lines.append("")
            
            # åˆ—ä¿¡æ¯
            if len(df.columns) <= 20:
                lines.append("**åˆ—å**: " + ", ".join(f"`{col}`" for col in df.columns))
                lines.append("")
            
            # æ•°æ®è¡¨æ ¼
            if not df.empty:
                markdown_table = self._dataframe_to_markdown(df)
                lines.append(markdown_table)
            
            lines.append("")
            progress.update()
        
        progress.complete()
        
        # JSONæ‘˜è¦
        summary = self._create_summary(input_file, sheets)
        lines.append("---")
        lines.append("### æ–‡ä»¶æ‘˜è¦")
        lines.append("```json")
        lines.append(safe_json_dumps(summary, indent=2, ensure_ascii=False))
        lines.append("```")
        
        return "\n".join(lines)
    
    def _dataframe_to_markdown(self, df: pd.DataFrame) -> str:
        """å°†DataFrameè½¬æ¢ä¸ºMarkdownè¡¨æ ¼"""
        if df.empty:
            return "*ç©ºè¡¨æ ¼*"
        
        # å¤„ç†å¤§è¡¨æ ¼åˆ†é¡µ
        total_rows = len(df)
        if total_rows <= self.max_rows_per_page:
            return self._df_to_markdown_simple(df)
        else:
            result = []
            num_pages = (total_rows + self.max_rows_per_page - 1) // self.max_rows_per_page
            
            for page in range(num_pages):
                start_idx = page * self.max_rows_per_page
                end_idx = min((page + 1) * self.max_rows_per_page, total_rows)
                
                page_df = df.iloc[start_idx:end_idx]
                result.append(f"### ç¬¬ {page + 1} é¡µ ({start_idx + 1}-{end_idx} è¡Œ)")
                result.append("")
                result.append(self._df_to_markdown_simple(page_df))
                result.append("")
            
            return "\n".join(result)
    
    def _df_to_markdown_simple(self, df: pd.DataFrame) -> str:
        """ç®€å•çš„DataFrameè½¬Markdownå®ç°ï¼Œä¸ä¾èµ–tabulate"""
        if df.empty:
            return "*ç©ºè¡¨æ ¼*"
        
        # è·å–åˆ—å
        columns = df.columns.tolist()
        
        # æ„å»ºMarkdownè¡¨æ ¼
        lines = []
        
        # è¡¨å¤´
        header = "| " + " | ".join(str(col) for col in columns) + " |"
        lines.append(header)
        
        # åˆ†éš”çº¿
        separator = "| " + " | ".join(["---"] * len(columns)) + " |"
        lines.append(separator)
        
        # æ•°æ®è¡Œ
        for _, row in df.iterrows():
            # å¤„ç†æ¯ä¸ªå•å…ƒæ ¼çš„å€¼ï¼Œé¿å…Noneå’ŒNaN
            row_values = []
            for col in columns:
                value = row[col]
                if pd.isna(value):
                    row_values.append("")
                else:
                    # è½¬ä¹‰ç®¡é“ç¬¦ï¼Œé¿å…ç ´åè¡¨æ ¼ç»“æ„
                    row_values.append(str(value).replace("|", "\\|"))
            
            row_line = "| " + " | ".join(row_values) + " |"
            lines.append(row_line)
        
        return "\n".join(lines)
    
    def _create_summary(self, input_file: Path, sheets: Dict[str, pd.DataFrame]) -> Dict:
        """åˆ›å»ºæ–‡ä»¶æ‘˜è¦"""
        total_rows = sum(len(df) for df in sheets.values())
        total_columns = sum(len(df.columns) for df in sheets.values())
        
        sheets_info = {}
        for sheet_name, df in sheets.items():
            sheets_info[sheet_name] = {
                "rows": len(df),
                "columns": len(df.columns),
                "column_names": df.columns.tolist()
            }
        
        return {
            "file_name": input_file.name,
            "file_path": str(input_file),
            "file_hash": get_file_hash(input_file),
            "conversion_time": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "total_sheets": len(sheets),
            "total_rows": total_rows,
            "total_columns": total_columns,
            "sheets_info": sheets_info
        }
    
    def convert_directory(self, input_dir: str, output_dir: str, force: bool = False) -> Dict[str, bool]:
        """
        è½¬æ¢ç›®å½•ä¸‹çš„æ‰€æœ‰Excelæ–‡ä»¶
        
        Args:
            input_dir: è¾“å…¥ç›®å½•
            output_dir: è¾“å‡ºç›®å½•
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°è½¬æ¢
            
        Returns:
            è½¬æ¢ç»“æœå­—å…¸
        """
        results = {}
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        ensure_directory(output_dir)
        
        # æŸ¥æ‰¾æ‰€æœ‰Excelæ–‡ä»¶
        excel_extensions = ['.xlsx', '.xls', '.xlsm', '.xlsb']
        excel_files = []
        for ext in excel_extensions:
            excel_files.extend(Path(input_dir).glob(f"*{ext}"))
        
        if not excel_files:
            logger.warning(f"åœ¨ç›®å½• {input_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°Excelæ–‡ä»¶")
            return results
        
        logger.info(f"æ‰¾åˆ° {len(excel_files)} ä¸ªExcelæ–‡ä»¶")
        
        # å¤„ç†æ¯ä¸ªæ–‡ä»¶
        for excel_file in tqdm(excel_files, desc="å¤„ç†æ–‡ä»¶"):
            output_file = Path(output_dir) / f"{excel_file.stem}.md"
            success = self.convert_single_file(str(excel_file), str(output_file), force)
            results[excel_file.name] = success
        
        return results


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='å°†Excelæ–‡ä»¶è½¬æ¢ä¸ºMarkdownæ ¼å¼ - æ”¹è¿›ç‰ˆ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # è½¬æ¢å•ä¸ªæ–‡ä»¶
  python xlsx2md_improved.py -i data.xlsx -o data.md
  
  # æ‰¹é‡è½¬æ¢ç›®å½•
  python xlsx2md_improved.py -d ./excel_files -od ./markdown_output
  
  # å¼ºåˆ¶é‡æ–°è½¬æ¢
  python xlsx2md_improved.py -i data.xlsx -o data.md -f
        """
    )
    
    parser.add_argument('--input', '-i', type=str, help='è¾“å…¥Excelæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', type=str, help='è¾“å‡ºMarkdownæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--dir', '-d', type=str, help='è¾“å…¥ç›®å½•è·¯å¾„ï¼ˆè½¬æ¢æ‰€æœ‰Excelæ–‡ä»¶ï¼‰')
    parser.add_argument('--output_dir', '-od', type=str, default='./markdown_output',
                       help='è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆé»˜è®¤: ./markdown_outputï¼‰')
    parser.add_argument('--chunk_size', '-c', type=int, default=1000,
                       help='åˆ†å—å¤„ç†çš„è¡Œæ•°ï¼ˆé»˜è®¤: 1000ï¼‰')
    parser.add_argument('--max_rows', '-m', type=int, default=500,
                       help='æ¯ä¸ªMarkdowné¡µé¢çš„æœ€å¤§è¡Œæ•°ï¼ˆé»˜è®¤: 500ï¼‰')
    parser.add_argument('--force', '-f', action='store_true',
                       help='å¼ºåˆ¶é‡æ–°è½¬æ¢ï¼Œå³ä½¿è¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨')
    parser.add_argument('--verbose', '-v', action='store_true',
                       help='è¯¦ç»†è¾“å‡ºæ¨¡å¼')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    log_level = "DEBUG" if args.verbose else "INFO"
    setup_logging(level=log_level)
    
    # åˆ›å»ºè½¬æ¢å™¨
    converter = ExcelToMarkdownConverter(
        chunk_size=args.chunk_size,
        max_rows_per_page=args.max_rows
    )
    
    # å¤„ç†å•ä¸ªæ–‡ä»¶
    if args.input:
        if not args.output:
            # è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            input_path = Path(args.input)
            args.output = f"{input_path.stem}.md"
        
        success = converter.convert_single_file(args.input, args.output, args.force)
        sys.exit(0 if success else 1)
    
    # å¤„ç†ç›®å½•
    elif args.dir:
        results = converter.convert_directory(args.dir, args.output_dir, args.force)
        
        # ç»Ÿè®¡ç»“æœ
        total = len(results)
        successful = sum(1 for success in results.values() if success)
        
        print(f"\n{'='*50}")
        print(f"è½¬æ¢å®Œæˆ!")
        print(f"æ€»æ–‡ä»¶æ•°: {total}")
        print(f"æˆåŠŸ: {successful}")
        print(f"å¤±è´¥: {total - successful}")
        print(f"{'='*50}")
        
        sys.exit(0 if successful == total else 1)
    
    else:
        parser.print_help()
        sys.exit(1)


if __name__ == '__main__':
    main()