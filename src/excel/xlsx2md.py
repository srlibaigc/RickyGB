#!/usr/bin/env python3
"""
XLSX to Markdown Converter
å°†Excelæ–‡ä»¶è½¬æ¢ä¸ºMarkdownæ ¼å¼ï¼Œä¾¿äºå¯¼å…¥å¤§æ¨¡å‹å’ŒæŸ¥çœ‹ã€‚
ä¿®å¤ç‰ˆæœ¬ï¼šæ”¯æŒ.xlsæ–‡ä»¶å¹¶å¢åŠ å¹‚ç­‰æ£€æµ‹
ä¿®å¤JSONåºåˆ—åŒ–é—®é¢˜
"""

import argparse
import os
import sys
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import warnings
from tqdm import tqdm
import json
import hashlib

# å¯¼å…¥å®‰å…¨çš„JSONå·¥å…·
try:
    from json_utils import safe_json_dumps, safe_json_loads
    JSON_UTILS_AVAILABLE = True
except ImportError:
    JSON_UTILS_AVAILABLE = False
    # å›é€€åˆ°æ ‡å‡†jsonå‡½æ•°
    import json
    safe_json_dumps = json.dumps
    safe_json_loads = json.loads

warnings.filterwarnings('ignore')


class ExcelToMarkdownConverter:
    """Excelæ–‡ä»¶è½¬Markdownè½¬æ¢å™¨ - ä¿®å¤ç‰ˆæœ¬"""

    def __init__(self, chunk_size: int = 1000, max_rows_per_page: int = 500):
        """
        åˆå§‹åŒ–è½¬æ¢å™¨

        Args:
            chunk_size: åˆ†å—å¤„ç†çš„è¡Œæ•°
            max_rows_per_page: æ¯ä¸ªMarkdowné¡µé¢çš„æœ€å¤§è¡Œæ•°
        """
        self.chunk_size = chunk_size
        self.max_rows_per_page = max_rows_per_page

    def get_file_extension(self, file_path: str) -> str:
        """è·å–æ–‡ä»¶æ‰©å±•å"""
        return Path(file_path).suffix.lower()

    def get_engine_for_file(self, file_path: str) -> str:
        """æ ¹æ®æ–‡ä»¶æ‰©å±•åè·å–åˆé€‚çš„å¼•æ“"""
        ext = self.get_file_extension(file_path)

        if ext == '.xlsx':
            return 'openpyxl'
        elif ext == '.xls':
            # å°è¯•ä½¿ç”¨xlrdå¼•æ“ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨openpyxl
            try:
                import xlrd
                return 'xlrd'
            except ImportError:
                print("è­¦å‘Š: xlrdæœªå®‰è£…ï¼Œå°è¯•ä½¿ç”¨openpyxlè¯»å–.xlsæ–‡ä»¶")
                return 'openpyxl'
        else:
            # é»˜è®¤ä½¿ç”¨openpyxl
            return 'openpyxl'

    def read_excel_file(self, file_path: str) -> Dict:
        """
        è¯»å–Excelæ–‡ä»¶ï¼Œå¤„ç†å¤šä¸ªsheeté¡µ - å¢å¼ºç‰ˆæœ¬

        Args:
            file_path: Excelæ–‡ä»¶è·¯å¾„

        Returns:
            åŒ…å«sheetåå’ŒDataFrameçš„å­—å…¸
        """
        file_ext = self.get_file_extension(file_path)
        file_name = Path(file_path).name

        # å°è¯•çš„å¼•æ“é¡ºåº
        engines_to_try = []

        if file_ext == '.xlsx':
            engines_to_try = ['openpyxl', 'xlrd']
        elif file_ext == '.xls':
            engines_to_try = ['xlrd', 'openpyxl']
        else:
            engines_to_try = ['openpyxl', 'xlrd']

        last_error = None

        for engine in engines_to_try:
            try:
                print(f"å°è¯•ä½¿ç”¨ {engine} å¼•æ“è¯»å– {file_name}...")

                # ä½¿ç”¨å½“å‰å¼•æ“è¯»å–Excelæ–‡ä»¶
                excel_file = pd.ExcelFile(file_path, engine=engine)
                sheets = {}

                for sheet_name in excel_file.sheet_names:
                    try:
                        # è¯»å–æ¯ä¸ªsheeté¡µ
                        df = pd.read_excel(
                            excel_file,
                            sheet_name=sheet_name,
                            dtype=str,  # å°†æ‰€æœ‰æ•°æ®è¯»ä¸ºå­—ç¬¦ä¸²ï¼Œä¿æŒåŸå§‹æ ¼å¼
                            na_filter=False,  # ä¸å°†ç©ºå­—ç¬¦ä¸²è½¬ä¸ºNaN
                            engine=engine
                        )
                        sheets[sheet_name] = df
                        print(f"  âœ“ è¯»å–sheeté¡µ: {sheet_name} ({len(df)}è¡ŒÃ—{len(df.columns)}åˆ—)")

                    except Exception as e:
                        print(f"  âœ— è¯»å–sheeté¡µ {sheet_name} æ—¶å‡ºé”™: {e}")
                        # å°è¯•ä½¿ç”¨ä¸åŒçš„å‚æ•°è¯»å–
                        try:
                            df = pd.read_excel(
                                excel_file,
                                sheet_name=sheet_name,
                                dtype=object,  # ä½¿ç”¨objectç±»å‹
                                na_filter=False,
                                engine=engine
                            )
                            sheets[sheet_name] = df
                            print(f"  âœ“ ä½¿ç”¨å¤‡ç”¨å‚æ•°è¯»å–sheeté¡µ: {sheet_name}")
                        except Exception as e2:
                            print(f"  âœ— å¤‡ç”¨å‚æ•°ä¹Ÿå¤±è´¥: {e2}")
                            # åˆ›å»ºç©ºçš„DataFrame
                            sheets[sheet_name] = pd.DataFrame()

                print(f"âœ“ ä½¿ç”¨ {engine} å¼•æ“æˆåŠŸè¯»å– {file_name}")
                return sheets

            except Exception as e:
                last_error = e
                print(f"âœ— ä½¿ç”¨ {engine} å¼•æ“å¤±è´¥: {e}")
                continue

        # æ‰€æœ‰å¼•æ“éƒ½å¤±è´¥
        print(f"âŒ æ‰€æœ‰å¼•æ“éƒ½æ— æ³•è¯»å–æ–‡ä»¶ {file_name}")
        print(f"æœ€åé”™è¯¯: {last_error}")
        return {}

    def detect_merged_cells(self, file_path: str, sheet_name: str) -> List[Tuple]:
        """
        æ£€æµ‹åˆå¹¶å•å…ƒæ ¼ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        å®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦ä½¿ç”¨openpyxlç›´æ¥è¯»å–æ¥è·å–å‡†ç¡®çš„åˆå¹¶å•å…ƒæ ¼ä¿¡æ¯

        Args:
            file_path: Excelæ–‡ä»¶è·¯å¾„
            sheet_name: sheeté¡µåç§°

        Returns:
            åˆå¹¶å•å…ƒæ ¼çš„åˆ—è¡¨ï¼Œæ ¼å¼ä¸º[(start_row, start_col, end_row, end_col), ...]
        """
        # è¿™é‡Œè¿”å›ç©ºåˆ—è¡¨ï¼Œå®é™…å®ç°éœ€è¦ä½¿ç”¨openpyxl
        # from openpyxl import load_workbook
        # wb = load_workbook(file_path, data_only=True)
        # ws = wb[sheet_name]
        # return ws.merged_cells.ranges
        return []

    def dataframe_to_markdown_table(self, df: pd.DataFrame,
                                   sheet_name: str = "",
                                   page_num: int = 1,
                                   total_pages: int = 1) -> str:
        """
        å°†DataFrameè½¬æ¢ä¸ºMarkdownè¡¨æ ¼

        Args:
            df: DataFrameæ•°æ®
            sheet_name: sheeté¡µåç§°
            page_num: å½“å‰é¡µç 
            total_pages: æ€»é¡µæ•°

        Returns:
            Markdownæ ¼å¼çš„è¡¨æ ¼å­—ç¬¦ä¸²
        """
        if df.empty:
            return f"### {sheet_name} (ç©ºè¡¨æ ¼)\n\n"

        # è·å–åˆ—å
        headers = df.columns.tolist()

        # åˆ›å»ºMarkdownè¡¨æ ¼å¤´éƒ¨
        markdown_lines = []

        # æ·»åŠ æ ‡é¢˜
        if sheet_name:
            markdown_lines.append(f"## ğŸ“‹ {sheet_name}")
            if total_pages > 1:
                markdown_lines.append(f"*é¡µé¢ {page_num}/{total_pages}*")
            markdown_lines.append("")

        # è¡¨æ ¼å¤´éƒ¨
        header_line = "| " + " | ".join(str(h) for h in headers) + " |"
        separator_line = "| " + " | ".join(["---"] * len(headers)) + " |"

        markdown_lines.append(header_line)
        markdown_lines.append(separator_line)

        # æ·»åŠ æ•°æ®è¡Œ
        for _, row in df.iterrows():
            row_values = []
            for col in headers:
                value = row[col]
                # å¤„ç†NaNå’ŒNoneå€¼
                if pd.isna(value) or value is None:
                    row_values.append("")
                else:
                    # è½¬ä¹‰Markdownç‰¹æ®Šå­—ç¬¦
                    cell_value = str(value).replace("|", "\\|").replace("\n", "<br>")
                    row_values.append(cell_value)

            row_line = "| " + " | ".join(row_values) + " |"
            markdown_lines.append(row_line)

        markdown_lines.append("")  # ç©ºè¡Œåˆ†éš”
        return "\n".join(markdown_lines)

    def process_large_dataframe(self, df: pd.DataFrame, sheet_name: str) -> List[str]:
        """
        å¤„ç†å¤§å‹DataFrameï¼Œåˆ†é¡µç”ŸæˆMarkdown

        Args:
            df: åŸå§‹DataFrame
            sheet_name: sheeté¡µåç§°

        Returns:
            åˆ†é¡µçš„Markdownå­—ç¬¦ä¸²åˆ—è¡¨
        """
        if df.empty:
            return [self.dataframe_to_markdown_table(df, sheet_name)]

        total_rows = len(df)
        if total_rows <= self.max_rows_per_page:
            return [self.dataframe_to_markdown_table(df, sheet_name)]

        # åˆ†é¡µå¤„ç†
        pages = []
        num_pages = (total_rows + self.max_rows_per_page - 1) // self.max_rows_per_page

        for page in range(num_pages):
            start_idx = page * self.max_rows_per_page
            end_idx = min((page + 1) * self.max_rows_per_page, total_rows)
            page_df = df.iloc[start_idx:end_idx]

            page_md = self.dataframe_to_markdown_table(
                page_df, sheet_name, page + 1, num_pages
            )
            pages.append(page_md)

        return pages

    def calculate_file_hash(self, file_path: str) -> str:
        """è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼ï¼Œç”¨äºå¹‚ç­‰æ£€æµ‹"""
        try:
            with open(file_path, 'rb') as f:
                file_hash = hashlib.md5(f.read()).hexdigest()
            return file_hash
        except Exception as e:
            print(f"è®¡ç®—æ–‡ä»¶å“ˆå¸Œæ—¶å‡ºé”™: {e}")
            return ""

    def check_if_already_converted(self, input_file: Path, output_file: Path) -> bool:
        """
        æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç»è½¬æ¢è¿‡ï¼ˆå¹‚ç­‰æ£€æµ‹ï¼‰- å¢å¼ºç‰ˆæœ¬
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            True: å·²ç»è½¬æ¢è¿‡ï¼Œæ— éœ€å†æ¬¡è½¬æ¢
            False: éœ€è¦è½¬æ¢
        """
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not output_file.exists():
            return False
        
        try:
            # è¯»å–è¾“å‡ºæ–‡ä»¶çš„å…ƒæ•°æ®
            with open(output_file, 'r', encoding='utf-8') as f:
                content = f.read(10000)  # è¯»å–æ›´å¤šå†…å®¹ç¡®ä¿æ‰¾åˆ°å…ƒæ•°æ®
            
            input_filename = input_file.name
            input_stem = input_file.stem
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æºæ–‡ä»¶åï¼ˆå¤šç§å¯èƒ½çš„æ ¼å¼ï¼‰
            patterns_to_check = [
                f"æºæ–‡ä»¶: `{input_filename}`",
                f"**æºæ–‡ä»¶:** `{input_filename}`",
                f"Excelæ–‡ä»¶è½¬æ¢ç»“æœ: {input_filename}",
                f"# Excelæ–‡ä»¶è½¬æ¢ç»“æœ: {input_filename}",
                f"æ–‡ä»¶åç§°: {input_filename}",
                f"**æ–‡ä»¶åç§°:** {input_filename}",
            ]
            
            for pattern in patterns_to_check:
                if pattern in content:
                    print(f"âœ“ æ£€æµ‹åˆ°å·²è½¬æ¢æ–‡ä»¶: {input_filename} (åŒ¹é…æ¨¡å¼: {pattern})")
                    return True
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
            if input_stem and f"{input_stem}" in content:
                # è¿›ä¸€æ­¥ç¡®è®¤è¿™æ˜¯æ­£ç¡®çš„æ–‡ä»¶
                lines = content.split('\n')
                for line in lines[:20]:  # åªæ£€æŸ¥å‰20è¡Œ
                    if input_filename in line or input_stem in line:
                        print(f"âœ“ æ£€æµ‹åˆ°å·²è½¬æ¢æ–‡ä»¶: {input_filename} (åœ¨å†…å®¹ä¸­æ‰¾åˆ°åŒ¹é…)")
                        return True
            
            # æ£€æŸ¥æ–‡ä»¶æ‘˜è¦ä¸­çš„JSON
            if '"file_name":' in content:
                import json
                import re
                # å°è¯•æå–JSONéƒ¨åˆ†
                json_match = re.search(r'```json\s*(.*?)\s*```', content, re.DOTALL)
                if json_match:
                    try:
                        summary = safe_json_loads(json_match.group(1), default={})
                        if summary.get('file_name') == input_filename:
                            print(f"âœ“ æ£€æµ‹åˆ°å·²è½¬æ¢æ–‡ä»¶: {input_filename} (JSONæ‘˜è¦åŒ¹é…)")
                            return True
                    except:
                        pass
            
            return False
                
        except Exception as e:
            print(f"æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return False

    def convert_single_file(self, input_path: str, output_path: str, force: bool = False) -> bool:
        """
        è½¬æ¢å•ä¸ªExcelæ–‡ä»¶ - å¢åŠ å¹‚ç­‰æ£€æµ‹

        Args:
            input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°è½¬æ¢

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            input_file = Path(input_path)
            output_file = Path(output_path)

            print(f"å¤„ç†æ–‡ä»¶: {input_file.name}")

            # å¹‚ç­‰æ£€æµ‹ï¼šæ£€æŸ¥æ˜¯å¦å·²ç»è½¬æ¢è¿‡
            if not force and self.check_if_already_converted(input_file, output_file):
                return True

            # è¯»å–Excelæ–‡ä»¶
            sheets = self.read_excel_file(input_path)
            if not sheets:
                print(f"æ–‡ä»¶ {input_file.name} ä¸­æ²¡æœ‰æ•°æ®æˆ–è¯»å–å¤±è´¥")
                return False

            # ç”ŸæˆMarkdownå†…å®¹
            markdown_content = []
            markdown_content.append(f"# Excelæ–‡ä»¶è½¬æ¢ç»“æœ: {input_file.name}")
            markdown_content.append(f"**æºæ–‡ä»¶:** `{input_path}`")
            markdown_content.append(f"**è½¬æ¢æ—¶é—´:** {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
            markdown_content.append(f"**Sheeté¡µæ•°é‡:** {len(sheets)}")

            # æ·»åŠ æ–‡ä»¶å“ˆå¸Œï¼ˆç”¨äºå¹‚ç­‰æ£€æµ‹ï¼‰
            file_hash = self.calculate_file_hash(input_path)
            if file_hash:
                markdown_content.append(f"**æ–‡ä»¶å“ˆå¸Œ:** `{file_hash}`")

            markdown_content.append("")
            markdown_content.append("---")
            markdown_content.append("")

            # å¤„ç†æ¯ä¸ªsheeté¡µ
            for sheet_name, df in tqdm(sheets.items(), desc="å¤„ç†Sheeté¡µ"):
                markdown_content.append(f"## ğŸ“„ Sheet: {sheet_name}")
                markdown_content.append(f"**è¡Œæ•°:** {len(df)}, **åˆ—æ•°:** {len(df.columns)}")
                markdown_content.append("")

                # åˆ†é¡µå¤„ç†å¤§å‹è¡¨æ ¼
                pages = self.process_large_dataframe(df, sheet_name)
                for page in pages:
                    markdown_content.append(page)

                markdown_content.append("---")
                markdown_content.append("")

            # æ·»åŠ æ–‡ä»¶æ‘˜è¦
            markdown_content.append("## ğŸ“Š æ–‡ä»¶æ‘˜è¦")
            markdown_content.append("```json")
            summary = {
                "file_name": input_file.name,
                "file_hash": file_hash,
                "total_sheets": len(sheets),
                "conversion_time": pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
                "sheets_info": {
                    sheet_name: {
                        "rows": len(df),
                        "columns": len(df.columns.tolist()),
                        "column_names": df.columns.tolist()
                    }
                    for sheet_name, df in sheets.items()
                }
            }
            markdown_content.append(safe_json_dumps(summary, indent=2, ensure_ascii=False))
            markdown_content.append("```")

            # å†™å…¥è¾“å‡ºæ–‡ä»¶
            output_file.parent.mkdir(parents=True, exist_ok=True)
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write("\n".join(markdown_content))

            print(f"âœ“ è½¬æ¢å®Œæˆ: {output_file}")
            return True

        except Exception as e:
            print(f"è½¬æ¢æ–‡ä»¶ {input_path} æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return False

    def convert_directory(self, input_dir: str, output_dir: str, force: bool = False) -> Dict[str, bool]:
        """
        è½¬æ¢ç›®å½•ä¸‹çš„æ‰€æœ‰Excelæ–‡ä»¶ - å¢åŠ å¹‚ç­‰æ£€æµ‹

        Args:
            input_dir: è¾“å…¥ç›®å½•
            output_dir: è¾“å‡ºç›®å½•
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°è½¬æ¢æ‰€æœ‰æ–‡ä»¶

        Returns:
            è½¬æ¢ç»“æœå­—å…¸ {æ–‡ä»¶å: æ˜¯å¦æˆåŠŸ}
        """
        results = {}

        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # æŸ¥æ‰¾æ‰€æœ‰Excelæ–‡ä»¶
        excel_extensions = ['.xlsx', '.xls', '.xlsm', '.xlsb']
        excel_files = []
        for ext in excel_extensions:
            excel_files.extend(Path(input_dir).glob(f"*{ext}"))

        if not excel_files:
            print(f"åœ¨ç›®å½• {input_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°Excelæ–‡ä»¶")
            print(f"æ”¯æŒçš„æ‰©å±•å: {', '.join(excel_extensions)}")
            return results

        print(f"æ‰¾åˆ° {len(excel_files)} ä¸ªExcelæ–‡ä»¶")

        # å¤„ç†æ¯ä¸ªæ–‡ä»¶
        for excel_file in tqdm(excel_files, desc="å¤„ç†æ–‡ä»¶"):
            output_file = output_path / f"{excel_file.stem}.md"
            success = self.convert_single_file(str(excel_file), str(output_file), force)
            results[excel_file.name] = success

        return results


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å°†Excelæ–‡ä»¶è½¬æ¢ä¸ºMarkdownæ ¼å¼ - ä¿®å¤ç‰ˆæœ¬')
    parser.add_argument('--input', '-i', type=str, help='è¾“å…¥Excelæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', type=str, help='è¾“å‡ºMarkdownæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--dir', '-d', type=str, help='è¾“å…¥ç›®å½•è·¯å¾„ï¼ˆè½¬æ¢æ‰€æœ‰Excelæ–‡ä»¶ï¼‰')
    parser.add_argument('--output_dir', '-od', type=str, default='./markdown_output',
                       help='è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆé»˜è®¤: ./markdown_outputï¼‰')
    parser.add_argument('--chunk_size', '-c', type=int, default=1000,
                       help='åˆ†å—å¤„ç†çš„è¡Œæ•°ï¼ˆé»˜è®¤: 1000ï¼‰')
    parser.add_argument('--max_rows', '-m', type=int, default=500,
                       help='æ¯ä¸ªMarkdowné¡µé¢çš„æœ€å¤§è¡Œæ•°ï¼ˆé»˜è®¤: 500ï¼‰')
    parser.add_argument('--force', '-f', action='store_true',
                       help='å¼ºåˆ¶é‡æ–°è½¬æ¢ï¼Œå³ä½¿è¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨')

    args = parser.parse_args()

    # åˆ›å»ºè½¬æ¢å™¨
    converter = ExcelToMarkdownConverter(
        chunk_size=args.chunk_size,
        max_rows_per_page=args.max_rows
    )

    # å¤„ç†å•ä¸ªæ–‡ä»¶
    if args.input:
        if not args.output:
            # è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            input_path = Path(args.input)
            args.output = f"{input_path.stem}.md"

        success = converter.convert_single_file(args.input, args.output, args.force)
        sys.exit(0 if success else 1)

    # å¤„ç†ç›®å½•
    elif args.dir:
        results = converter.convert_directory(args.dir, args.output_dir, args.force)

        # ç»Ÿè®¡ç»“æœ
        total = len(results)
        successful = sum(1 for success in results.values() if success)

        print(f"\n{'='*50}")
        print(f"è½¬æ¢å®Œæˆ!")
        print(f"æˆåŠŸ: {successful}/{total}")
        print(f"å¤±è´¥: {total - successful}")

        if total - successful > 0:
            print("\nå¤±è´¥çš„æ–‡ä»¶:")
            for filename, success in results.items():
                if not success:
                    print(f"  - {filename}")

        sys.exit(0 if successful == total else 1)

    else:
        parser.print_help()
        sys.exit(1)


if __name__ == "__main__":
    main()