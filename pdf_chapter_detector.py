#!/usr/bin/env python3
"""
PDFç« èŠ‚æ£€æµ‹å™¨ - Sprint 3
æ™ºèƒ½è¯†åˆ«PDFä¸­çš„ç« èŠ‚è¾¹ç•Œ
"""

import re
import logging
from pathlib import Path
from typing import List, Dict, Tuple, Optional

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ChapterDetector:
    """ç« èŠ‚æ£€æµ‹å™¨ - æ™ºèƒ½è¯†åˆ«ç« èŠ‚è¾¹ç•Œ"""
    
    def __init__(self, min_chapter_pages=5, max_chapter_pages=50):
        """
        åˆå§‹åŒ–ç« èŠ‚æ£€æµ‹å™¨
        
        Args:
            min_chapter_pages: æœ€å°ç« èŠ‚é¡µæ•°
            max_chapter_pages: æœ€å¤§ç« èŠ‚é¡µæ•°
        """
        self.min_chapter_pages = min_chapter_pages
        self.max_chapter_pages = max_chapter_pages
        
        # ç« èŠ‚æ ‡é¢˜æ¨¡å¼
        self.chapter_patterns = [
            # ä¸­æ–‡ç« èŠ‚æ¨¡å¼
            r'ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+ç« ',
            r'ç¬¬[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡\d]+èŠ‚',
            r'[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]ã€',  # ä¸€ã€äºŒã€
            r'\d+[\.ã€]',  # 1. 1ã€
            r'[A-Z]\.',  # A. B.
            
            # è‹±æ–‡ç« èŠ‚æ¨¡å¼
            r'Chapter\s+\d+',
            r'Chapter\s+[IVXLCDM]+',  # Roman numerals
            r'Section\s+\d+',
            r'Part\s+\d+',
            
            # é€šç”¨æ¨¡å¼
            r'^\s*\d+\.\s+',  # æ•°å­—å¼€å¤´
            r'^\s*[A-Z]\s+',  # å¤§å†™å­—æ¯å¼€å¤´
        ]
        
        # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
        self.patterns = [re.compile(pattern, re.IGNORECASE) for pattern in self.chapter_patterns]
        
        logger.info(f"åˆå§‹åŒ–ç« èŠ‚æ£€æµ‹å™¨")
        logger.info(f"æœ€å°ç« èŠ‚é¡µæ•°: {min_chapter_pages}")
        logger.info(f"æœ€å¤§ç« èŠ‚é¡µæ•°: {max_chapter_pages}")
    
    def detect_from_text(self, page_texts: Dict[int, str]) -> List[int]:
        """
        ä»é¡µé¢æ–‡æœ¬ä¸­æ£€æµ‹ç« èŠ‚è¾¹ç•Œ
        
        Args:
            page_texts: é¡µé¢ç¼–å·åˆ°æ–‡æœ¬çš„æ˜ å°„
            
        Returns:
            List[int]: ç« èŠ‚èµ·å§‹é¡µç åˆ—è¡¨
        """
        if not page_texts:
            return []
        
        total_pages = max(page_texts.keys()) + 1
        logger.info(f"å¼€å§‹ç« èŠ‚æ£€æµ‹ï¼Œæ€»é¡µæ•°: {total_pages}")
        
        # æ”¶é›†æ‰€æœ‰å¯èƒ½çš„ç« èŠ‚èµ·å§‹é¡µ
        candidate_pages = []
        
        for page_num, text in page_texts.items():
            if not text or len(text.strip()) < 10:
                continue
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºç« èŠ‚èµ·å§‹
            is_chapter_start, confidence, reason = self._is_chapter_start(text, page_num)
            
            if is_chapter_start:
                candidate_pages.append({
                    'page': page_num,
                    'confidence': confidence,
                    'reason': reason,
                    'text_preview': text[:100]
                })
        
        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ç« èŠ‚ï¼Œä½¿ç”¨å›ºå®šé¡µæ•°
        if not candidate_pages:
            logger.info("æœªæ£€æµ‹åˆ°ç« èŠ‚æ ‡é¢˜ï¼Œä½¿ç”¨å›ºå®šé¡µæ•°æ‹†åˆ†")
            return self._fallback_to_fixed_pages(total_pages)
        
        # æŒ‰é¡µç æ’åº
        candidate_pages.sort(key=lambda x: x['page'])
        
        logger.info(f"æ£€æµ‹åˆ° {len(candidate_pages)} ä¸ªå¯èƒ½çš„ç« èŠ‚èµ·å§‹")
        for i, candidate in enumerate(candidate_pages[:5]):  # æ˜¾ç¤ºå‰5ä¸ª
            logger.info(f"  å€™é€‰ {i+1}: é¡µ {candidate['page']+1}, ç½®ä¿¡åº¦: {candidate['confidence']:.2f}, åŸå› : {candidate['reason']}")
        
        # é€‰æ‹©ç« èŠ‚è¾¹ç•Œ
        chapter_boundaries = self._select_chapter_boundaries(candidate_pages, total_pages)
        
        logger.info(f"ç¡®å®šç« èŠ‚è¾¹ç•Œ: {len(chapter_boundaries)} ä¸ªç« èŠ‚")
        for i, boundary in enumerate(chapter_boundaries):
            logger.info(f"  ç¬¬ {i+1} ç« èµ·å§‹: é¡µ {boundary+1}")
        
        return chapter_boundaries
    
    def _is_chapter_start(self, text: str, page_num: int) -> Tuple[bool, float, str]:
        """
        åˆ¤æ–­æ–‡æœ¬æ˜¯å¦ä¸ºç« èŠ‚èµ·å§‹
        
        Returns:
            (æ˜¯å¦ç« èŠ‚èµ·å§‹, ç½®ä¿¡åº¦, åŸå› )
        """
        text = text.strip()
        
        # è§„åˆ™1: æ£€æŸ¥ç« èŠ‚æ¨¡å¼
        for pattern in self.patterns:
            if pattern.search(text):
                # æ£€æŸ¥æ˜¯å¦åœ¨æ–‡æœ¬å¼€å¤´é™„è¿‘
                lines = text.split('\n')
                for line in lines[:3]:  # åªæ£€æŸ¥å‰3è¡Œ
                    if pattern.search(line.strip()):
                        match_text = pattern.search(line.strip()).group()
                        return True, 0.8, f"åŒ¹é…æ¨¡å¼: {match_text}"
        
        # è§„åˆ™2: æ£€æŸ¥æ ‡é¢˜ç‰¹å¾ï¼ˆçŸ­æ–‡æœ¬ã€å¤§å†™å¼€å¤´ç­‰ï¼‰
        lines = text.split('\n')
        first_line = lines[0].strip() if lines else ""
        
        if len(first_line) < 100 and len(first_line) > 5:
            # æ£€æŸ¥æ˜¯å¦åƒæ ‡é¢˜
            title_features = 0
            
            # ç‰¹å¾1: ä»¥æ•°å­—æˆ–å¤§å†™å­—æ¯å¼€å¤´
            if first_line and (first_line[0].isdigit() or first_line[0].isupper()):
                title_features += 1
            
            # ç‰¹å¾2: ä¸åŒ…å«å¥å·ï¼ˆå¯èƒ½ä¸æ˜¯æ®µè½ï¼‰
            if '.' not in first_line:
                title_features += 1
            
            # ç‰¹å¾3: è¡Œæ•°å°‘
            if len(lines) <= 3:
                title_features += 1
            
            if title_features >= 2:
                return True, 0.6, f"æ ‡é¢˜ç‰¹å¾: {title_features}/3"
        
        # è§„åˆ™3: é¡µé¢ä½ç½®ï¼ˆæ–‡æ¡£å¼€å¤´å‡ é¡µå¯èƒ½æ˜¯ç« èŠ‚ï¼‰
        if page_num < 5:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«"ç›®å½•"ã€"å‰è¨€"ç­‰
            if any(keyword in text for keyword in ['ç›®å½•', 'å‰è¨€', 'å¼•è¨€', 'æ‘˜è¦', 'abstract', 'contents']):
                return True, 0.7, "æ–‡æ¡£èµ·å§‹éƒ¨åˆ†"
        
        return False, 0.0, "ä¸ç¬¦åˆç« èŠ‚ç‰¹å¾"
    
    def _select_chapter_boundaries(self, candidates: List[Dict], total_pages: int) -> List[int]:
        """
        ä»å€™é€‰é¡µé¢ä¸­é€‰æ‹©ç« èŠ‚è¾¹ç•Œ
        
        Args:
            candidates: å€™é€‰é¡µé¢åˆ—è¡¨
            total_pages: æ€»é¡µæ•°
            
        Returns:
            List[int]: é€‰æ‹©çš„ç« èŠ‚è¾¹ç•Œ
        """
        if not candidates:
            return self._fallback_to_fixed_pages(total_pages)
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        candidates.sort(key=lambda x: x['confidence'], reverse=True)
        
        selected_boundaries = []
        
        # æ€»æ˜¯ä»ç¬¬0é¡µå¼€å§‹
        selected_boundaries.append(0)
        
        # é€‰æ‹©é«˜ç½®ä¿¡åº¦çš„å€™é€‰
        high_confidence = [c for c in candidates if c['confidence'] > 0.7]
        
        for candidate in high_confidence:
            page_num = candidate['page']
            
            # æ£€æŸ¥æ˜¯å¦ä¸å·²æœ‰è¾¹ç•Œå¤ªè¿‘
            if selected_boundaries:
                last_boundary = selected_boundaries[-1]
                pages_since_last = page_num - last_boundary
                
                if pages_since_last >= self.min_chapter_pages and pages_since_last <= self.max_chapter_pages:
                    selected_boundaries.append(page_num)
                elif pages_since_last < self.min_chapter_pages:
                    logger.debug(f"è·³è¿‡é¡µ {page_num+1}: è·ç¦»ä¸Šä¸€ç« èŠ‚å¤ªè¿‘ ({pages_since_last} é¡µ)")
                else:
                    logger.debug(f"è·³è¿‡é¡µ {page_num+1}: è·ç¦»ä¸Šä¸€ç« èŠ‚å¤ªè¿œ ({pages_since_last} é¡µ)")
            else:
                selected_boundaries.append(page_num)
        
        # ç¡®ä¿è¦†ç›–æ‰€æœ‰é¡µé¢
        if selected_boundaries[-1] + self.max_chapter_pages < total_pages:
            # æ·»åŠ ä¸­é—´è¾¹ç•Œ
            current_page = selected_boundaries[-1]
            while current_page + self.max_chapter_pages < total_pages:
                current_page += self.max_chapter_pages
                selected_boundaries.append(current_page)
        
        # æ’åºå¹¶å»é‡
        selected_boundaries = sorted(set(selected_boundaries))
        
        return selected_boundaries
    
    def _fallback_to_fixed_pages(self, total_pages: int) -> List[int]:
        """å›é€€åˆ°å›ºå®šé¡µæ•°æ‹†åˆ†"""
        boundaries = []
        avg_pages = (self.min_chapter_pages + self.max_chapter_pages) // 2
        
        for start in range(0, total_pages, avg_pages):
            boundaries.append(start)
        
        return boundaries
    
    def analyze_document_structure(self, page_texts: Dict[int, str]) -> Dict:
        """
        åˆ†ææ–‡æ¡£ç»“æ„
        
        Returns:
            Dict: ç»“æ„åˆ†æç»“æœ
        """
        if not page_texts:
            return {'error': 'æ— é¡µé¢æ–‡æœ¬'}
        
        total_pages = max(page_texts.keys()) + 1
        
        # æ£€æµ‹ç« èŠ‚
        chapter_boundaries = self.detect_from_text(page_texts)
        
        # åˆ†ææ–‡æœ¬ç‰¹å¾
        text_stats = self._analyze_text_statistics(page_texts)
        
        # æ„å»ºç»“æ„
        structure = {
            'total_pages': total_pages,
            'detected_chapters': len(chapter_boundaries),
            'chapter_boundaries': chapter_boundaries,
            'text_statistics': text_stats,
            'detection_method': 'smart' if len(chapter_boundaries) > 1 else 'fixed',
            'confidence': self._calculate_confidence(chapter_boundaries, page_texts)
        }
        
        # æ·»åŠ ç« èŠ‚è¯¦æƒ…
        chapters = []
        for i in range(len(chapter_boundaries)):
            start_page = chapter_boundaries[i]
            end_page = chapter_boundaries[i + 1] if i + 1 < len(chapter_boundaries) else total_pages
            
            # æå–ç« èŠ‚æ ‡é¢˜
            chapter_title = "æœªçŸ¥ç« èŠ‚"
            if start_page in page_texts:
                first_page_text = page_texts[start_page]
                lines = first_page_text.split('\n')
                if lines:
                    chapter_title = lines[0].strip()[:50]
            
            chapters.append({
                'chapter_number': i + 1,
                'start_page': start_page,
                'end_page': end_page,
                'page_count': end_page - start_page,
                'title': chapter_title
            })
        
        structure['chapters'] = chapters
        
        return structure
    
    def _analyze_text_statistics(self, page_texts: Dict[int, str]) -> Dict:
        """åˆ†ææ–‡æœ¬ç»Ÿè®¡ä¿¡æ¯"""
        if not page_texts:
            return {}
        
        total_chars = sum(len(text) for text in page_texts.values())
        avg_chars_per_page = total_chars / len(page_texts) if page_texts else 0
        
        # è®¡ç®—æ–‡æœ¬å¯†åº¦å˜åŒ–
        char_counts = [len(page_texts.get(i, '')) for i in range(max(page_texts.keys()) + 1)]
        
        return {
            'total_pages_analyzed': len(page_texts),
            'total_characters': total_chars,
            'avg_characters_per_page': avg_chars_per_page,
            'max_characters_per_page': max(char_counts) if char_counts else 0,
            'min_characters_per_page': min([c for c in char_counts if c > 0]) if char_counts else 0
        }
    
    def _calculate_confidence(self, boundaries: List[int], page_texts: Dict[int, str]) -> float:
        """è®¡ç®—æ£€æµ‹ç½®ä¿¡åº¦"""
        if len(boundaries) <= 1:
            return 0.3  # ä½ç½®ä¿¡åº¦
        
        # åŸºäºè¾¹ç•Œæ•°é‡å’Œåˆ†å¸ƒè®¡ç®—ç½®ä¿¡åº¦
        total_pages = max(page_texts.keys()) + 1 if page_texts else 1
        
        # æ£€æŸ¥è¾¹ç•Œåˆ†å¸ƒæ˜¯å¦åˆç†
        chapter_lengths = []
        for i in range(len(boundaries) - 1):
            length = boundaries[i + 1] - boundaries[i]
            chapter_lengths.append(length)
        
        if chapter_lengths:
            avg_length = sum(chapter_lengths) / len(chapter_lengths)
            # è®¡ç®—é•¿åº¦ä¸€è‡´æ€§
            variance = sum((length - avg_length) ** 2 for length in chapter_lengths) / len(chapter_lengths)
            consistency = 1.0 / (1.0 + variance)  # æ–¹å·®è¶Šå°ï¼Œä¸€è‡´æ€§è¶Šé«˜
            
            # ç»¼åˆç½®ä¿¡åº¦
            confidence = 0.3 + 0.5 * consistency + 0.2 * (len(boundaries) / (total_pages / 20))
            return min(confidence, 1.0)
        
        return 0.5

def test_chapter_detection():
    """æµ‹è¯•ç« èŠ‚æ£€æµ‹åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•ç« èŠ‚æ£€æµ‹åŠŸèƒ½")
    
    detector = ChapterDetector()
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_texts = {
        0: "ç¬¬ä¸€ç«  å¼•è¨€\n\næœ¬æ–‡ä»‹ç»PDFç« èŠ‚æ£€æµ‹æŠ€æœ¯...",
        1: "è¿™æ˜¯å¼•è¨€éƒ¨åˆ†çš„ç»§ç»­å†…å®¹...",
        2: "æ›´å¤šå¼•è¨€å†…å®¹...",
        3: "ç¬¬äºŒç«  æŠ€æœ¯å®ç°\n\næœ¬ç« ä»‹ç»å…·ä½“å®ç°æ–¹æ³•...",
        4: "æŠ€æœ¯ç»†èŠ‚éƒ¨åˆ†...",
        5: "æ›´å¤šæŠ€æœ¯å†…å®¹...",
        6: "ç¬¬ä¸‰ç«  å®éªŒç»“æœ\n\nå±•ç¤ºå®éªŒæ•°æ®å’Œç»“æœ...",
        7: "ç»“æœåˆ†æ...",
        8: "ç»“è®ºéƒ¨åˆ†...",
    }
    
    print(f"æµ‹è¯•æ•°æ®: {len(test_texts)} é¡µ")
    
    # æ£€æµ‹ç« èŠ‚
    boundaries = detector.detect_from_text(test_texts)
    
    print(f"\næ£€æµ‹ç»“æœ:")
    print(f"ç« èŠ‚è¾¹ç•Œ: {boundaries}")
    print(f"ç« èŠ‚æ•°: {len(boundaries)}")
    
    # åˆ†æç»“æ„
    structure = detector.analyze_document_structure(test_texts)
    
    print(f"\næ–‡æ¡£ç»“æ„åˆ†æ:")
    print(f"æ£€æµ‹æ–¹æ³•: {structure['detection_method']}")
    print(f"ç½®ä¿¡åº¦: {structure['confidence']:.2f}")
    
    print(f"\nç« èŠ‚è¯¦æƒ…:")
    for chapter in structure['chapters']:
        print(f"  ç¬¬{chapter['chapter_number']}ç« : é¡µ {chapter['start_page']+1}-{chapter['end_page']}, "
              f"{chapter['page_count']}é¡µ, æ ‡é¢˜: {chapter['title']}")
    
    return len(boundaries) > 1

def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(description='PDFç« èŠ‚æ£€æµ‹å™¨')
    parser.add_argument('--test', action='store_true', help='æµ‹è¯•åŠŸèƒ½')
    
    args = parser.parse_args()
    
    if args.test:
        success = test_chapter_detection()
        if success:
            print("\nâœ… ç« èŠ‚æ£€æµ‹æµ‹è¯•é€šè¿‡")
            return 0
        else:
            print("\nâŒ ç« èŠ‚æ£€æµ‹æµ‹è¯•å¤±è´¥")
            return 1
    
    parser.print_help()

if __name__ == "__main__":
    main()